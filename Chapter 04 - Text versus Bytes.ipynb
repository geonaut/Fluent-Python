{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text versus Bytes\n",
    "\n",
    "Python 3 drew distinction between strings of human text and sequences of raw bytes.\n",
    "\n",
    "## What is a character?\n",
    "\n",
    "Python 3 => str = unicode characters & is similar to Py2 unicode object\n",
    "- ---------------------------------\n",
    "Python 2 => unicode object = unicode characters\n",
    "\n",
    "Python 2 => str = raw bytes\n",
    "\n",
    "The Unicode standard explicitly separates the identity of characters from specific byte representations.\n",
    "\n",
    "-  Unicode code point is a number from 0 to 1,114,111 (base 10)\n",
    "-  Represented in the Unicode standard as 4 to 6 hexadecimal digits with a “U+” prefix.\n",
    "-  About 10% of the valid code points have characters assigned to them\n",
    "-  The actual bytes that represent a character depend on the encoding in use, where encoding is an algorithm that converts code points to byte sequences and vice-versa. \n",
    "    -  The code point for A (U+0041) = \\x41 in the UTF-8 encoding & \\x41\\x00 in UTF-16LE encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b'caf\\xc3\\xa9'\n",
      "5\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "#cafe, with a extended ASCII character\n",
    "s = 'café'\n",
    "#has 4 unicode characters\n",
    "print(len(s))\n",
    "#change encoding to UTF-8\n",
    "b = s.encode('utf8')\n",
    "print(b)\n",
    "#now é is represented by 2 bytes, so len = 5\n",
    "print(len(b))\n",
    "print(b.decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New binary sequences in Py3\n",
    "\n",
    "-  bytes (Immutable - items are int 0-255)\n",
    "-  bytearray (Mutable - items are int 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "99\n",
      "b'c'\n",
      "bytearray(b'caf\\xc3\\xa9')\n",
      "5\n",
      "bytearray(b'\\xa9')\n"
     ]
    }
   ],
   "source": [
    "#create a byte string using \\xc3\\xa9 for é (not \\xcc\\x81!!)\n",
    "cafe = bytes('café', encoding='utf_8')\n",
    "#prints as utf-8 byte literals - NOT code point, which starts with U+\n",
    "print(cafe)\n",
    "#prints first character, but represented as ASCII decimal. C = 99 in ASCII decimal\n",
    "print(cafe[0])\n",
    "# slice produces output of same type\n",
    "print(cafe[:1])\n",
    "cafe_arr = bytearray(cafe)\n",
    "#byte array displays as bytearray(b....). \"caf\" are in the ASCII range, so printed\n",
    "print(cafe_arr)\n",
    "#cafe_arr has 5 bytes - 2 for é\n",
    "print(len(cafe_arr))\n",
    "#... , so the last item in a bytestring is the last of the 2 é bytes - i.e. \\xa9\n",
    "print(cafe_arr[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  For bytes in the printable ASCII range — from space to ~ — the ASCII character itself is used.\n",
    "-  For bytes corresponding to tab, newline, carriage return and \\, the escape sequences \\t, \\n, \\r and \\\\ are used.\n",
    "-  For every other byte value, an hexadecimal escape sequence is used, e.g. \\x00 is the null byte.\n",
    "\n",
    "Both bytes and bytearray support every str method except those that do formatting (format, format_map). This means that you can use familiar string methods like endswith, replace, strip, translate, upper etc.\n",
    "\n",
    "The other ways of building bytes or bytearray instances are calling their constructors with:\n",
    "-  a str and an encoding keyword argument.\n",
    "-  an iterable providing items with values from 0 to 255.\n",
    "-  a single integer, to create a binary sequence of that size initialized with null bytes3.\n",
    "-  an object that implements the buffer protocol (eg. bytes, bytearray, memoryview, array.array); this copies the bytes from the source object to the newly created binary sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1K\\xce\\xa9'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing from Hex to UTF-8\n",
    "print(bytes.fromhex('31 4B CE A9'))\n",
    "\n",
    "# Initializing bytes from the raw data of an array.\n",
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2]) \n",
    "octets = bytes(numbers)\n",
    "octets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structs and memory views\n",
    "\n",
    "The struct module provides functions to parse packed bytes into a tuple of fields of different types and to perform the opposite conversion, from a tuple into packed bytes. \n",
    "\n",
    "Memoryview class does not let you create or store byte sequences, but provides shared memory access to slices of data from other binary sequences, packed arrays and buffers such as PIL images, without copying the bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'GIF87aY\\x02\\xcb\\x00'\n",
      "(b'GIF', b'87a', 601, 203)\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "#struct format: < little-endian; 3s3s two sequences of 3 bytes; HH two 16-bit integers.\n",
    "fmt = '<3s3sHH'\n",
    "\n",
    "#python.gif = 601x203px\n",
    "with open('python.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read())\n",
    "\n",
    "header = img[:10]\n",
    "\n",
    "print(bytes(header))\n",
    "#type, version, width height\n",
    "print(struct.unpack(fmt, header))\n",
    "#release memory associated with memory view instances\n",
    "del header\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic encoders/decoders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for codec in ['latin_1','utf_8', 'utf_16']:\n",
    "    # Make sure n = ñ from Latin1, not ñ from OSX\n",
    "    print(codec, 'El Niño'.encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Sa\\xcc\\x83o Paulo'\n",
      "b'\\xff\\xfeS\\x00a\\x00\\x03\\x03o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00'\n",
      "b'Sao Paulo'\n",
      "b'Sa?o Paulo'\n",
      "b'Sa&#771;o Paulo'\n",
      "Montréal\n",
      "Montrιal\n",
      "MontrИal\n",
      "Montr�al\n"
     ]
    }
   ],
   "source": [
    "city = 'São Paulo'\n",
    "print(city.encode('utf_8'))\n",
    "print(city.encode('utf_16'))\n",
    "# print(city.encode('iso8859_1'))\n",
    "#silently skip unknown chars\n",
    "print(city.encode('cp437', errors='ignore'))\n",
    "#replace with ?\n",
    "print(city.encode('cp437', errors='replace'))\n",
    "#replace with XML\n",
    "print(city.encode('cp437', errors='xmlcharrefreplace'))\n",
    "\n",
    "##Coping with UnicodeDecodeError\n",
    "\n",
    "octets = b'Montr\\xe9al' \n",
    "print(octets.decode('cp1252'))\n",
    "print(octets.decode('iso8859_7'))\n",
    "print(octets.decode('koi8_r'))\n",
    "#print(octets.decode('utf_8')) #'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte\n",
    "print(octets.decode('utf_8', errors='replace'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chardet can be used to detect encoding, based on common bytes\n",
    "\n",
    "## Endianness, and byte order\n",
    "\n",
    "One big advantage of UTF-8 is that it produces the same byte sequence regardless of machine endianness, so no BOM is needed. \n",
    "\n",
    "## Handling text files\n",
    "\n",
    "-  Bytes should be decoded to str as early as possible on input, e.g. when opening a file for reading. B\n",
    "-  Business logic of your program, where text handling is done exclusively on str objects. You should never be encoding or de‐ coding in the middle of other processing. \n",
    "-  On output, the str are encoded to bytes as late as possible.\n",
    "\n",
    "Python 3 makes it easier to follow the advice of the Unicode sandwich, because the open built-in does the necessary decoding when reading and encoding when writing files in text mode, so all you get from my_file.read() and pass to my_file.write(text) are str objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>\n",
      "4\n",
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='US-ASCII'>\n",
      "US-ASCII\n",
      "<_io.BufferedReader name='cafe.txt'>\n",
      "b'caf\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "fp = open('cafe.txt', 'w', encoding='utf_8')\n",
    "#returns TextIOWrapper object\n",
    "print(fp)\n",
    "print(fp.write('café'))\n",
    "fp.close\n",
    "import os\n",
    "os.stat('cafe.txt').st_size\n",
    "#opens with locale default encoding (ASCII for me)\n",
    "fp2 = open('cafe.txt')\n",
    "print(fp2)\n",
    "print(fp2.encoding)\n",
    "fp3 = open('cafe.txt', 'rb')\n",
    "print(fp3)\n",
    "#read the raw bytes\n",
    "print(fp3.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'US-ASCII'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'US-ASCII'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'US-ASCII'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "import sys, locale\n",
    "expressions = \"\"\"\n",
    "        locale.getpreferredencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.stderr.encoding\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "#locale.getpreferredencoding() = default from locale\n",
    "#my_file.encoding = file gets from default localte\n",
    "#sys.stdout.isatty() = output is not going to console\n",
    "#sys.stdout.encoding = therefore console output is UTF-8\n",
    "#sys.stdin.isatty()\n",
    "#sys.stdin.encoding\n",
    "#sys.stderr.isatty()\n",
    "#sys.stderr.encoding\n",
    "#sys.getdefaultencoding() # default from internal Python setting\n",
    "#sys.getfilesystemencoding() # is mbcs on Windows. On GNU/Linux and OSX all of these encodings... \n",
    "    #are set to UTF-8 by default, and have been for several years, so I/O handles all Unicode characters. \n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression) \n",
    "    print(expression.rjust(30), '->', repr(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best advice about encoding defaults is: do not rely on them!\n",
    "\n",
    "## Normalizing Unicode for saner comparisons\n",
    "\n",
    "NFC (Normalization Form C) composes the code points to produce the shortest equiv‐ alent string, while NFD decomposes, expanding composed characters into base char‐ acters and separate combining characters. Both of these normalizations make compar‐ isons work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4\n",
      "4 4\n",
      "True\n",
      "5 5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café' # composed \"e\" with acute accent\n",
    "s2 = 'café' # decomposed \"e\" and acute accent\n",
    "print(len(s1), len(s2))\n",
    "#using NFC\n",
    "print(len(normalize('NFC', s1)), len(normalize('NFC', s2)))\n",
    "print(normalize('NFC', s1) == normalize('NFC', s2))\n",
    "#Using NFD\n",
    "print(len(normalize('NFD', s1)), len(normalize('NFD', s2)))\n",
    "print(normalize('NFD', s1) == normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHM SIGN\n",
      "GREEK CAPITAL LETTER OMEGA\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "#ohn the unit\n",
    "ohm = '\\u2126'\n",
    "print(name(ohm))\n",
    "#normalise to greek char\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "print(name(ohm_c))\n",
    "#originals don't match\n",
    "print(ohm == ohm_c)\n",
    "#normalised do\n",
    "print(normalize('NFC', ohm) == normalize('NFC', ohm_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1⁄2\n",
      "42\n",
      "µ μ\n",
      "181 956\n",
      "MICRO SIGN GREEK SMALL LETTER MU\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name \n",
    "\n",
    "half = '½'\n",
    "print(normalize('NFKC', half))\n",
    "four_squared = '4²'\n",
    "print(normalize('NFKC', four_squared))\n",
    "#the micro sign is considered a “compatibility character”.\n",
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKC', micro) \n",
    "print(micro, micro_kc)\n",
    "print(ord(micro), ord(micro_kc))\n",
    "print(name(micro), name(micro_kc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NFKC and NFKD forms, each compatibility character is replaced by a “compat‐ ibility decomposition” of one or more characters that are considered a “preferred” rep‐ resentation, even if there is some formatting loss.\n",
    "\n",
    "## Case folding\n",
    "\n",
    "Case folding is essentially converting all text to lowercase, with some additional transformations. For any string s containing only latin-1 characters, s.casefold() produces the same result as s.lower(), with only two exceptions: the micro sign 'μ' is changed to the Greek lower case mu (which looks the same in most fonts) and the German Eszett or “sharp s” (ß) becomes “ss”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEK SMALL LETTER MU\n",
      "µ μ\n",
      "LATIN SMALL LETTER SHARP S\n",
      "ß ss\n"
     ]
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "micro_cf = micro.casefold() \n",
    "print(name(micro_cf))\n",
    "print(micro, micro_cf)\n",
    "eszett = 'ß'\n",
    "print(name(eszett))\n",
    "eszett_cf = eszett.casefold()\n",
    "print(eszett, eszett_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize \n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==\n",
    "            normalize('NFC', str2).casefold())\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "#different é\n",
    "print(s1 == s2)\n",
    "#normalise them - ok\n",
    "print(nfc_equal(s1, s2))\n",
    "#normalising doesn't work, because both have valid, but different code points\n",
    "print(nfc_equal('A', 'a'))\n",
    "\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "#not equal\n",
    "print(s3 == s4)\n",
    "#normalised are equal\n",
    "print(nfc_equal(s3, s4))\n",
    "#folding means transformation for ezzet\n",
    "print(fold_equal(s3, s4))\n",
    "# é is normalised\n",
    "print(fold_equal(s1, s2))\n",
    "# cases are matched during casefold\n",
    "print(fold_equal('A', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme “normalization”: taking out diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of ŒtkerTM caffe latte • bowl of acai.”\n",
      "\"Herr Voß: - ½ cup of OEtkerTM caffè latte - bowl of açaí.\"\n",
      "\"Herr Voss: - 1⁄2 cup of OEtkerTM caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt) \n",
    "    shaved = ''.join(c for c in norm_txt\n",
    "        if not unicodedata.combining(c)) \n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\" \n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base: \n",
    "            continue # ignore diacritic on Latin base char\n",
    "        keepers.append(c)\n",
    "        # if it isn't combining char, it's a new base char \n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters \n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—~›\"\"\",\n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({\n",
    "    '€': '<euro>',\n",
    "    'Œ': 'OE',\n",
    "    '‰': '<per mille>',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\" \n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt)) \n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks)\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of ŒtkerTM caffè latte • bowl of açaí.”'\n",
    "\n",
    "print(shave_marks(order))\n",
    "print(dewinize(order))\n",
    "print(asciize(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acerola', 'açaí', 'atemoia', 'cajá', 'caju']\n",
      "['acerola', 'açaí', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "## Doesn't work on OSX?\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "print(sorted(fruits))\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "fruits2 = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits2, key=locale.strxfrm)\n",
    "print(sorted_fruits)\n",
    "\n",
    "#Module not found - need to install Django?\n",
    "#import pyuca\n",
    "#coll = pyuca.Collator()\n",
    "#fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "#sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "#sorted_fruits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Unicode database\n",
    "\n",
    "The Unicode standard provides an entire database that includes not only the table mapping code points to character names, but also lot of metadata about the individual characters and how they are related. For example:\n",
    "\n",
    "-  the Unicode database records whether a character is printable, is a letter, is a decimal digit or is some other numeric symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "#print the unicode codepoint\n",
    "for char in sample: print('U+%04x' % ord(char),\n",
    "    #print the char\n",
    "    char.center(6),\n",
    "        #Show re_dig if character matches the r'\\d' regex.\n",
    "        're_dig' if re_digit.match(char) else '-',\n",
    "        #Show isdig if char.isdigit() is True.\n",
    "        'isdig' if char.isdigit() else '-',\n",
    "        #Show isnum if char.isnumeric() is True.\n",
    "        'isnum' if char.isnumeric() else '-', \n",
    "        format(unicodedata.numeric(char), '5.2f'), \n",
    "        unicodedata.name(char),\n",
    "        sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## str versus bytes in regular expressions\n",
    "\n",
    "you can use regular expressions on str and bytes but in the second case bytes outside of the ASCII range are treated as non-digits and non-word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      " str : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      " bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      " str : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      " bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\" \n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "text_bytes = text_str.encode('utf_8')\n",
    "print('Text', repr(text_str), sep='\\n ') \n",
    "print('Numbers')\n",
    "print(' str :', re_numbers_str.findall(text_str)) \n",
    "print(' bytes:', re_numbers_bytes.findall(text_bytes)) \n",
    "print('Words')\n",
    "print(' str :', re_words_str.findall(text_str)) \n",
    "print(' bytes:', re_words_bytes.findall(text_bytes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
